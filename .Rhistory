rm(list = ls())
library(tidyverse)
above10 <- read_csv("data/Homeboy Dropoff - above10_04202018-04202023.csv")[, 1:8]
above10below15_exceptNYC <- c("Indianapolis", "Washington", "Columbus", "Albuquerque", "Atlanta", "Denver", "San Antonio", "Detroit", "Louisville",  "Birmingham", "New Orleans")
rm(list = ls())
library(tidyverse)
above10 <- read_csv("data/Homeboy Dropoff - above10_04202018-04202023.csv")[, 1:8]
above10below15_exceptNYC <- c("Indianapolis", "Washington", "Columbus", "Albuquerque", "Atlanta", "Denver", "San Antonio", "Detroit", "Louisville",  "Birmingham", "New Orleans")
above10$City.Or.County <- as.factor(above10$City.Or.County)
above10$Year <- format(above10$Incident.Date, "%Y")
above10$Response.type <- as.factor(above10$Response.type)
View(above10)
rm(list = ls())
library(tidyverse)
above10 <- read_csv("data/Homeboy Dropoff - above10_04202018-04202023.csv")
above10below15_exceptNYC <- c("Indianapolis", "Washington", "Columbus", "Albuquerque", "Atlanta", "Denver", "San Antonio", "Detroit", "Louisville",  "Birmingham", "New Orleans")
above10$City.Or.County <- as.factor(above10$City.Or.County)
above10$Year <- format(above10$Incident.Date, "%Y")
above10$Response.type <- as.factor(above10$Response.type)
as.factor(above10$Response.type)
above10$Response.type <- as.factor(above10$Resopnse.type)
rm(list = ls())
library(tidyverse)
above10 <- read_csv("data/Homeboy Dropoff - above10_04202018-04202023.csv")
above10below15_exceptNYC <- c("Indianapolis", "Washington", "Columbus", "Albuquerque", "Atlanta", "Denver", "San Antonio", "Detroit", "Louisville",  "Birmingham", "New Orleans")
above10$City.Or.County <- as.factor(above10$City.Or.County)
above10$Year <- format(above10$Incident.Date, "%Y")
above10$Response.type <- as.factor(above10$Resopnse.type)
View(above10)
rm(list = ls())
library(tidyverse)
above10 <- read_csv("data/Homeboy Dropoff - above10_04202018-04202023.csv") %>%
filter(grepl('uicide', Detail))
above10below15_exceptNYC <- c("Indianapolis", "Washington", "Columbus", "Albuquerque", "Atlanta", "Denver", "San Antonio", "Detroit", "Louisville",  "Birmingham", "New Orleans")
above10$City.Or.County <- as.factor(above10$City.Or.County)
above10$Year <- format(above10$Incident.Date, "%Y")
above10$Response.type <- as.factor(above10$Resopnse.type)
View(above10)
rm(list = ls())
library(tidyverse)
above10 <- read_csv("data/Homeboy Dropoff - above10_04202018-04202023.csv") %>%
filter(!grepl('uicide', Detail))
above10below15_exceptNYC <- c("Indianapolis", "Washington", "Columbus", "Albuquerque", "Atlanta", "Denver", "San Antonio", "Detroit", "Louisville",  "Birmingham", "New Orleans")
above10$City.Or.County <- as.factor(above10$City.Or.County)
above10$Year <- format(above10$Incident.Date, "%Y")
above10$Response.type <- as.factor(above10$Resopnse.type)
## ---------------------------
##
## Script name: merge2
## Purpose of script: Expand the 04202020-04202023 data created through merge.R and sort.R script to 04202018-04202023
## Author: Cal Chengqi Fang
## Date Created: 2023-07-07
##
## Copyright (c) Cal Chengqi Fang, 2023
## Email: cal.cf@uchicago.edu
##
## ---------------------------
##
## Notes:
##
##
## ---------------------------
## set working directory for Mac and PC
setwd("/Users/atchoo/Desktop/Homeboy")  # Cal's working directory (mac)
# setwd("C:/Users/")     # Cal's working directory (PC)
## ---------------------------
rm(list = ls())
options(scipen = 6, digits = 4)         # I prefer to view outputs in non-scientific notation
memory.limit(30000000)                  # this is needed on some PCs to increase memory allowance, but has no impact on macs.
## ---------------------------
## load up the packages we will need:  (uncomment as required)
require(tidyverse)
require(data.table)
# source("functions/packages.R")        # loads up all the packages we need
## ---------------------------
# STEP 1 Read in the cleaned 04202018-12312018 file
clean_2018 <- read_csv("data/clean_2018.csv")
# STEP 2 Create a tibble for 01012019-12312019 records
injured_2019 <- read.csv("data/OFFICER INVOLVED OFFICER INJURED IN 2019.csv",
colClasses = c("character", "character", "character", "character", "character", "character", "NULL", "NULL")) %>%
mutate(Outcome = "Injured") %>%
as_tibble()
injured_2019$Incident.Date <- lubridate::mdy(injured_2019$Incident.Date)
killed_2019 <- read.csv("data/OFFICER INVOLVED OFFICER KILLED IN 2019.csv",
colClasses = c("character", "character", "character", "character", "character", "character", "NULL", "NULL")) %>%
mutate(Outcome = "Killed") %>%
as_tibble()
killed_2019$Incident.Date <- lubridate::mdy(killed_2019$Incident.Date)
clean_2019 <- rbind(injured_2019, killed_2019)
# STEP 3 Create a tibble for 01012020-04192020 records
injured_2020 <- read.csv("data/OFFICER INVOLVED OFFICER INJURED IN 2020.csv",
colClasses = c("character", "character", "character", "character", "character", "character", "NULL", "NULL")) %>%
mutate(Outcome = "Injured") %>%
as_tibble()
injured_2020$Incident.Date <- lubridate::mdy(injured_2020$Incident.Date)
killed_2020 <- read.csv("data/OFFICER INVOLVED OFFICER KILLED IN 2020.csv",
colClasses = c("character", "character", "character", "character", "character", "character", "NULL", "NULL")) %>%
mutate(Outcome = "Killed") %>%
as_tibble()
killed_2020$Incident.Date <- lubridate::mdy(killed_2020$Incident.Date)
clean_2020 <- rbind(injured_2020, killed_2020) %>%
filter(Incident.Date < "2020-04-20")
# STEP 4 Read in the cleaned 04202020-04202023 file
clean_rest <- read_csv("data/Homeboy Dropoff - GVA_04202020-04202023.csv")
clean_rest$Incident.Date <- lubridate::mdy(clean_rest$Incident.Date)
# STEP 5 Combine all four tibbles together
clean <- bind_rows(clean_2018, clean_2019, clean_2020, clean_rest)
# STEP 6 Identify candidate cities
above10_list <- clean %>%
group_by(City.Or.County, State) %>%
summarise(casenum = n()) %>%
filter(casenum >= 10)
View(above10_list)
above10 %>%
group_by(State, City.Or.County, Year) %>%
summarise(Count = n()) %>%
pivot_wider(names_from = Year, values_from = Count)
rm(list = ls())
library(tidyverse)
above10 <- read_csv("data/Homeboy Dropoff - above10_04202018-04202023.csv") %>%
filter(!grepl('uicide', Detail))
above10below15_exceptNYC <- c("Indianapolis", "Washington", "Columbus", "Albuquerque", "Atlanta", "Denver", "San Antonio", "Detroit", "Louisville",  "Birmingham", "New Orleans")
above10$City.Or.County <- as.factor(above10$City.Or.County)
above10$Year <- format(above10$Incident.Date, "%Y")
above10$Response.type <- as.factor(above10$Resopnse.type)
above10 %>%
group_by(State, City.Or.County, Year) %>%
summarise(Count = n()) %>%
pivot_wider(names_from = Year, values_from = Count)
df <- above10 %>%
group_by(State, City.Or.County, Year) %>%
summarise(Count = n()) %>%
pivot_wider(names_from = Year, values_from = Count)
func <- function(z) if (is.numeric(z)) sum(z) else ''
sumrow <- as.data.frame(lapply(df, func))
knitr::kable(rbind(cbind(' '=' ', df),
cbind(' '='Total', sumrow)))
df <- above10 %>%
group_by(State, City.Or.County, Year) %>%
summarise(Count = n()) %>%
pivot_wider(names_from = Year, values_from = Count)
df %>%
summarise(across(where(is.character), ~"Total"),
across(where(is.numeric), ~sum(., na.rm = T)))
df <- above10 %>%
group_by(State, City.Or.County, Year) %>%
summarise(Count = n()) %>%
pivot_wider(names_from = Year, values_from = Count)
func <- function(z) if (is.numeric(z)) sum(z) else ''
df %>%
bind_rows(as.data.frame(lapply(df, func)))
func <- function(z) if (is.numeric(z)) sum(z) else ''
df <- above10 %>%
group_by(State, City.Or.County, Year) %>%
summarise(Count = n()) %>%
pivot_wider(names_from = Year, values_from = Count)
View(df)
func <- function(z) if (is.numeric(z)) sum(z) else ''
sumrow <- as.data.frame(lapply(df, func))
View(sumrow)
func <- function(z) if (is.numeric(z)) sum(z) else ''
df <- above10 %>%
group_by(State, City.Or.County, Year) %>%
summarise(Count = n()) %>%
pivot_wider(names_from = Year, values_from = Count)
func <- function(z) if (is.numeric(z)) sum(z, na.rm=TRUE) else ''
sumrow <- as.data.frame(lapply(df, func))
knitr::kable(rbind(df, sumrow))
rbind(df, sumrow)
cbind(df, sumrow)
above10 %>%
group_by(State, City.Or.County, Year) %>%
summarise(Count = n()) %>%
pivot_wider(names_from = Year, values_from = Count) %>%
mutate(Total = sum(2019:2022))
above10 %>%
group_by(State, City.Or.County, Year) %>%
summarise(Count = n()) %>%
pivot_wider(names_from = Year, values_from = Count) %>%
mutate(Total = sum(`2019`:`2022`))
above10 %>%
group_by(State, City.Or.County, Year) %>%
summarise(Count = n()) %>%
pivot_wider(names_from = Year, values_from = Count) %>%
mutate(Total = sum(c(`2019`, `2022`), na.rm=TRUE)) %>%
knitr::kable()
above10 %>%
group_by(State, City.Or.County, Year) %>%
summarise(Count = n()) %>%
pivot_wider(names_from = Year, values_from = Count) %>%
mutate(Total = sum(c(`2019`, `2020`, `2021`, `2022`, `2023`), na.rm=TRUE)) %>%
knitr::kable()
summary <- above10 %>%
group_by(City.Or.County, Response.type) %>%
summarise(Count = n()) %>%
pivot_wider(names_from = Resopnse.type, values_from = Count)
summary <- above10 %>%
group_by(City.Or.County, Response.type) %>%
summarise(Count = n()) %>%
pivot_wider(names_from = Response.type, values_from = Count)
View(summary)
unique(above10$Resopnse.type)
rm(list = ls())
library(tidyverse)
above10 <- read_csv("data/Homeboy Dropoff - above10_04202018-04202023.csv") %>%
filter(!grepl('uicide', Detail))
above10below15_exceptNYC <- c("Indianapolis", "Washington", "Columbus", "Albuquerque", "Atlanta", "Denver", "San Antonio", "Detroit", "Louisville",  "Birmingham", "New Orleans")
summary <- above10 %>%
group_by(City.Or.County, Response.type) %>%
summarise(Count = n()) %>%
pivot_wider(names_from = Response.type, values_from = Count) %>%
mutate(Total = sum(c(Unknown, `Police Self-transfer`, Others, Ambulance), na.rm=TRUE))
rm(list = ls())
library(tidyverse)
above10 <- read_csv("data/Homeboy Dropoff - above10_04202018-04202023.csv") %>%
filter(!grepl('uicide', Detail))
above10below15_exceptNYC <- c("Indianapolis", "Washington", "Columbus", "Albuquerque", "Atlanta", "Denver", "San Antonio", "Detroit", "Louisville",  "Birmingham", "New Orleans")
summary <- above10 %>%
group_by(City.Or.County, Response.type) %>%
summarise(Count = n()) %>%
pivot_wider(names_from = Response.type, values_from = Count) %>%
mutate(Total = sum(c(Unknown, `Police Self-transfer`, Others, Ambulance), na.rm=TRUE))
above10$City.Or.County <- as.factor(above10$City.Or.County)
above10$Year <- format(above10$Incident.Date, "%Y")
View(above10)
rm(list = ls())
library(tidyverse)
above10 <- read_csv("data/Homeboy Dropoff - above10_04202018-04202023.csv") %>%
filter(!grepl('uicide', Detail))
above10$Incident.Date <- as.Date(above10$Incident.Date, "%m/%d/%y")
above10below15_exceptNYC <- c("Indianapolis", "Washington", "Columbus", "Albuquerque", "Atlanta", "Denver", "San Antonio", "Detroit", "Louisville",  "Birmingham", "New Orleans")
summary <- above10 %>%
group_by(City.Or.County, Response.type) %>%
summarise(Count = n()) %>%
pivot_wider(names_from = Response.type, values_from = Count) %>%
mutate(Total = sum(c(Unknown, `Police Self-transfer`, Others, Ambulance), na.rm=TRUE))
above10$City.Or.County <- as.factor(above10$City.Or.County)
above10$Year <- format(above10$Incident.Date, "%Y")
above10$Response.type <- as.factor(above10$Resopnse.type)
rm(list = ls())
library(tidyverse)
above10 <- read_csv("data/Homeboy Dropoff - above10_04202018-04202023.csv") %>%
filter(!grepl('uicide', Detail))
above10$Incident.Date <- as.Date(above10$Incident.Date, "%m/%d/%y")
above10below15_exceptNYC <- c("Indianapolis", "Washington", "Columbus", "Albuquerque", "Atlanta", "Denver", "San Antonio", "Detroit", "Louisville",  "Birmingham", "New Orleans")
summary <- above10 %>%
group_by(City.Or.County, Response.type) %>%
summarise(Count = n()) %>%
pivot_wider(names_from = Response.type, values_from = Count) %>%
mutate(Total = sum(c(Unknown, `Police Self-transfer`, Others, Ambulance), na.rm=TRUE))
above10$City.Or.County <- as.factor(above10$City.Or.County)
above10$Year <- format(above10$Incident.Date, "%Y")
above10$Response.type <- as.factor(above10$Response.type)
View(summary)
rm(list = ls())
library(tidyverse)
above10 <- read_csv("data/Homeboy Dropoff - above10_04202018-04202023.csv") %>%
filter(!grepl('uicide', Detail))
above10$Incident.Date <- as.Date(above10$Incident.Date, "%m/%d/%y")
above10below15_exceptNYC <- c("Indianapolis", "Washington", "Columbus", "Albuquerque", "Atlanta", "Denver", "San Antonio", "Detroit", "Louisville",  "Birmingham", "New Orleans")
temp <- above10 %>%
group_by(City.Or.County, Response.type) %>%
summarise(Count = n()) %>%
pivot_wider(names_from = Response.type, values_from = Count) %>%
mutate(Total = sum(c(Unknown, `Police Self-transfer`, Others, Ambulance), na.rm=TRUE)) %>%
filter(Unknown <= 0.25*Total)
above10 <- above10 %>%
filter(City.Or.County %in% temp$City.Or.County)
above10$City.Or.County <- as.factor(above10$City.Or.County)
above10$Year <- format(above10$Incident.Date, "%Y")
above10$Response.type <- as.factor(above10$Response.type)
View(above10)
View(temp)
View(temp)
rm(list = ls())
library(tidyverse)
above10 <- read_csv("data/Homeboy Dropoff - above10_04202018-04202023.csv") %>%
filter(!grepl('uicide', Detail))
above10$Incident.Date <- as.Date(above10$Incident.Date, "%m/%d/%y")
above10below15_exceptNYC <- c("Indianapolis", "Washington", "Columbus", "Albuquerque", "Atlanta", "Denver", "San Antonio", "Detroit", "Louisville",  "Birmingham", "New Orleans")
temp <- above10 %>%
group_by(City.Or.County, Response.type) %>%
summarise(Count = n()) %>%
pivot_wider(names_from = Response.type, values_from = Count) %>%
mutate(Total = sum(c(Unknown, `Police Self-transfer`, Others, Ambulance), na.rm=TRUE)) %>%
filter(Unknown <= 0.25*Total)
above10_2 <- above10
above10 <- above10 %>%
filter(City.Or.County %in% temp$City.Or.County |
City.Or.County %in% c("Bronx", "Brooklyn", "Corona (Queens)", "New York (Manhattan)", "Staten Island"))
above10$City.Or.County <- as.factor(above10$City.Or.County)
above10$Year <- format(above10$Incident.Date, "%Y")
above10$Response.type <- as.factor(above10$Response.type)
above10 %>%
group_by(State, City.Or.County, Year) %>%
summarise(Count = n()) %>%
pivot_wider(names_from = Year, values_from = Count) %>%
mutate(Total = sum(c(`2019`, `2020`, `2021`, `2022`, `2023`), na.rm=TRUE)) %>%
knitr::kable()
above10_2 %>%
group_by(State, City.Or.County, Year) %>%
summarise(Count = n()) %>%
pivot_wider(names_from = Year, values_from = Count) %>%
mutate(Total = sum(c(`2019`, `2020`, `2021`, `2022`, `2023`), na.rm=TRUE)) %>%
knitr::kable()
sum(above10$Response.type == "Police Self-transfer")
147/300
View(df)
colSums(is.na(read.csv("/Users/atchoo/Documents/GitHub/CMSC35300_FinalProject/diabetes_NHANES_1999_2004.csv")))
colSums(is.na(read.csv("/Users/atchoo/Documents/GitHub/CMSC35300_FinalProject/diabetes_NHANES_1999_2004.csv")))
colSums(is.na(read.csv("/Users/atchoo/Documents/GitHub/CMSC35300_FinalProject/diabetes_NHANES_1999_2004.csv")))
## ---------------------------
##
## Script name: 04_clean.R
##
## Purpose of script: To clean the raw data scraped from the three agencies' websites.
##
## Author: Cal Chengqi Fang
##
## Date Created: 2024-01-05
##
## Copyright (c) Cal Chengqi Fang, 2023
## Email: cal.cf@uchicago.edu
##
## ---------------------------
##
## Notes:
##   1. CareCredit and Comenity's Alphaeon card both listed veterinary partners on their website
##      which is not of interest to us and needs to be dropped.
##   2. CareCredit and Comenity's Alphaeon card both listed very detailed specialty information for
##      some partners that provided multiple services on their website. I will split such specialty information
##      for later analysis. For instance, if a practice' specialty were "OB/GYN, Pediatrician", it would be split
##      to two rows with specialty being "OB/GYN" and "Pediatrician" and everything else the same.
##   3. Some specialty info were too detailed and not very important for this project so we are gonna regroup them.
##
## ---------------------------
## set working directory for Mac and PC
setwd("/Users/atchoo/Documents/GitHub/MedicalCreditCard")  # Cal's working directory (mac)
# setwd("C:/Users/")     # Cal's working directory (PC)
## ---------------------------
rm(list=ls())
options(scipen=6, digits=4)         # I prefer to view outputs in non-scientific notation
memory.limit(30000000)              # this is needed on some PCs to increase memory allowance, but has no impact on macs.
## ---------------------------
## load up the packages we will need:  (uncomment as required)
require(tidyverse)
## ---------------------------
# STEP 1
# Load the data and drop duplicates created from scrapping process
carecredit <- read_csv("results/carecredit.csv") %>%
distinct() %>%
rename(address=address1,
specialty=specialties) %>%
select(-location)
alphaeon <- read_csv("results/alphaeon.csv") %>%
distinct() %>%
rename(address=address1,
specialty=specialties) %>%
select(-location)
wellsfargoHA <- read_csv("results/wellsfargoHA.csv") %>%
distinct() %>%
rename(address=address1,
specialty=specialties) %>%
select(-location)
## ---------------------------
##
## Script name: 04_clean.R
##
## Purpose of script: To clean the raw data scraped from the three agencies' websites.
##
## Author: Cal Chengqi Fang
##
## Date Created: 2024-01-05
##
## Copyright (c) Cal Chengqi Fang, 2023
## Email: cal.cf@uchicago.edu
##
## ---------------------------
##
## Notes:
##   1. CareCredit and Comenity's Alphaeon card both listed veterinary partners on their website
##      which is not of interest to us and needs to be dropped.
##   2. CareCredit and Comenity's Alphaeon card both listed very detailed specialty information for
##      some partners that provided multiple services on their website. I will split such specialty information
##      for later analysis. For instance, if a practice' specialty were "OB/GYN, Pediatrician", it would be split
##      to two rows with specialty being "OB/GYN" and "Pediatrician" and everything else the same.
##   3. Some specialty info were too detailed and not very important for this project so we are gonna regroup them.
##
## ---------------------------
## set working directory for Mac and PC
setwd("/Users/atchoo/Documents/GitHub/MedicalCreditCard")  # Cal's working directory (mac)
# setwd("C:/Users/")     # Cal's working directory (PC)
## ---------------------------
rm(list=ls())
options(scipen=6, digits=4)         # I prefer to view outputs in non-scientific notation
memory.limit(30000000)              # this is needed on some PCs to increase memory allowance, but has no impact on macs.
## ---------------------------
## load up the packages we will need:  (uncomment as required)
require(tidyverse)
## ---------------------------
# STEP 1
# Load the data and drop duplicates created from scrapping process
carecredit <- read_csv("results/carecredit.csv") %>%
distinct() %>%
rename(address=address1,
specialty=specialties) %>%
select(-location)
alphaeon <- read_csv("results/alphaeon.csv") %>%
distinct() %>%
rename(address=address1,
specialty=specialties) %>%
select(-location)
wellsfargoHA <- read_csv("results/wellsfargoHA.csv") %>%
distinct() %>%
rename(address=address1,
specialty=specialties) %>%
select(-location)
# Drop more duplicates in the three card locator database
carecredit <- carecredit %>%
mutate(address = str_to_title(address),
city = str_to_title(city)) %>%
distinct(address, phone, .keep_all=TRUE)
alphaeon <- alphaeon %>%
mutate(address = str_to_title(address),
city = str_to_title(city)) %>%
distinct(address, phone, .keep_all=TRUE)
wellsfargoHA <- wellsfargoHA %>%
mutate(address = str_to_title(address),
city = str_to_title(city)) %>%
distinct(address, phone, .keep_all=TRUE)
# STEP 2
# Drop all animal-related practices in carecredit and alphaeon
carecredit <- carecredit %>%
filter(!grepl("Pet|Vet|Animal|Equine", specialty) &
!grepl("\\bPet\\b|\\bVet\\b|Veterinary|Veterinarian|Animal|Equine", name))
wellsfargoHA <- wellsfargoHA %>%
filter(!grepl("Veterinary", specialty))
# STEP 3
# Split long specialty descriptions in carecredit and alphaeon to multiple rows
carecredit <- carecredit %>%
separate_longer_delim(cols = specialty, delim = ", ") %>%
mutate(specialty = ifelse(specialty %in% c("Ear", "Nose & Throat"),
"Ear, Nose & Throat", specialty)) %>%
distinct() %>%
drop_na(specialty)
alphaeon <- alphaeon %>%
mutate(specialty = str_replace_all(specialty, "\\s{2,}|\\n", "")) %>%
separate_longer_delim(cols = specialty, delim = ",") %>%
distinct() %>%
drop_na(specialty)
# STEP 4 Regroup the specialty
# Rename some specialty for consistency
carecredit$specialty[carecredit$specialty=="Outpatient Surgery Center"] <- "Surgery Centers"
carecredit$specialty[carecredit$specialty=="Dermatologist"] <- "Dermatology"
carecredit$specialty[carecredit$specialty=="OB/GYN"] <- "Obstetrics & gynecology"
# Build a clean specialty list
raw_list <- unique(c(carecredit$specialty, alphaeon$specialty, wellsfargoHA$specialty))
dental <- grep("Den|dontist|dontics|Oral", raw_list, value=TRUE)
vision <- grep("Eye|Ophth|Cataract|LASIK|Retina|Optometrist|Vision", raw_list, value=TRUE)
audio <- grep("Hearing|Audio", raw_list, value=TRUE)
cosmetic <- grep("Hair|Cosmetic|Plastic|Aesthetics|Weight", raw_list, value=TRUE)
physical <- grep("Phy", raw_list, value=TRUE)
other <- grep("Cord|Other|Lice", raw_list, value=TRUE)
unrelated <- grep("Medspa|Spa|Beauty|Supplements|Mattresses|Funeral", raw_list, value=TRUE)
equipment <- grep("Equipment|Wheelchair|Prosthetics|Monitors", raw_list, value=TRUE)
marginmed <- grep("Pharm|Speech|Acupu|Chiro|Home", raw_list, value=TRUE)
rest <- raw_list %>%
setdiff(c(dental, vision, audio, cosmetic, physical, other, unrelated, equipment, marginmed))
regroup <- bind_rows(
data.frame(specialty = dental, specialty_re = "Dentistry"),
data.frame(specialty = vision, specialty_re = "Vision Medicine"),
data.frame(specialty = audio, specialty_re = "Audiology"),
data.frame(specialty = cosmetic, specialty_re = "Cosmetic Medicine"),
data.frame(specialty = physical, specialty_re = "Physical Medicine & Rehabilitation"),
data.frame(specialty = other, specialty_re = "Unknown/Others"),
data.frame(specialty = unrelated, specialty_re = "Unrelated"),
data.frame(specialty = equipment, specialty_re = "Medical Equipment"),
data.frame(specialty = marginmed, specialty_re = "Supplmental/Alternative Medicine"),
data.frame(specialty = rest, specialty_re = rest)
)
# Regroup and combine
carecredit_clean <- carecredit %>%
merge(regroup, all.x=TRUE) %>%
distinct() %>%
filter(!specialty_re %in% c("Unrelated", "Medical Equipment", "Unknown/Others"))
alphaeon_clean <- alphaeon %>%
merge(regroup, all.x=TRUE) %>%
distinct() %>%
filter(!specialty_re %in% c("Unrelated", "Medical Equipment", "Unknown/Others"))
wellsfargoHA_clean <- wellsfargoHA %>%
merge(regroup, all.x=TRUE) %>%
distinct() %>%
filter(!specialty_re %in% c("Unrelated", "Medical Equipment", "Unknown/Others"))
# STEP 5
# Bind the three dataframes
mcc_clean <- bind_rows(list(carecredit=carecredit_clean,
alphaeon=alphaeon_clean,
wellsfargoHA=wellsfargoHA_clean), .id = 'credit')
# Drop the duplicates caused by regrouping the specialty
mcc_clean <- mcc_clean %>%
select(-specialty) %>%
distinct()
# Duplicate suspect
test <- mcc_clean %>%
group_by(phone) %>%
summarize(count = n()) %>%
filter(count > 1)
# STEP 6
# Save the data
save(carecredit_clean, alphaeon_clean, wellsfargoHA_clean,
mcc_clean,
file="results/cleaned.Rdata")
